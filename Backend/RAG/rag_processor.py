# rag_processor.py
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings  # Modern paket
from langchain_chroma import Chroma  # Modern paket
import os
import warnings

# UyarÄ±larÄ± bastÄ±r
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=UserWarning)

class RAGProcessor:
    def __init__(self, pdfs_path="PDFs", vector_store_path="vector_store"):
        self.pdfs_path = pdfs_path
        self.vector_store_path = vector_store_path
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        self.vector_store = None
        
    def load_and_process_pdfs(self):
        """PDF'leri yÃ¼kle ve vektÃ¶r veritabanÄ± oluÅŸtur"""
        documents = []
        
        # PDFs klasÃ¶rÃ¼nÃ¼ kontrol et
        if not os.path.exists(self.pdfs_path):
            print(f"âŒ PDFs klasÃ¶rÃ¼ bulunamadÄ±: {self.pdfs_path}")
            return
        
        pdf_files = [f for f in os.listdir(self.pdfs_path) if f.endswith('.pdf')]
        if not pdf_files:
            print(f"âŒ PDFs klasÃ¶rÃ¼nde PDF dosyasÄ± bulunamadÄ±: {self.pdfs_path}")
            return
            
        print(f"ğŸ“š {len(pdf_files)} PDF dosyasÄ± bulundu: {pdf_files}")
        
        for pdf_file in pdf_files:
            try:
                pdf_path = os.path.join(self.pdfs_path, pdf_file)
                print(f"ğŸ“– Ä°ÅŸleniyor: {pdf_file}")
                loader = PyPDFLoader(pdf_path)
                documents.extend(loader.load())
                print(f"âœ… {pdf_file} baÅŸarÄ±yla yÃ¼klendi")
            except Exception as e:
                print(f"âŒ {pdf_file} yÃ¼klenirken hata: {e}")
        
        if not documents:
            print("âŒ HiÃ§ dokÃ¼man yÃ¼klenemedi!")
            return
            
        print(f"ğŸ“„ Toplam {len(documents)} sayfa yÃ¼klendi")
        
        # Metinleri bÃ¶l
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_documents(documents)
        print(f"âœ‚ï¸ {len(chunks)} metin parÃ§asÄ± oluÅŸturuldu")
        
        # ChromaDB ile vektÃ¶r veritabanÄ± oluÅŸtur
        print("ğŸ”§ VektÃ¶r veritabanÄ± oluÅŸturuluyor...")
        self.vector_store = Chroma.from_documents(
            documents=chunks,
            embedding=self.embeddings,
            persist_directory=self.vector_store_path
        )
        print("âœ… VektÃ¶r veritabanÄ± oluÅŸturuldu!")
        
    def search_similar(self, query, k=3):
        """Benzer dokÃ¼manlarÄ± ara"""
        if self.vector_store is None:
            if not os.path.exists(self.vector_store_path):
                print("âŒ VektÃ¶r veritabanÄ± bulunamadÄ±. Ã–nce PDF'leri iÅŸleyin.")
                return []
                
            print("ğŸ” VektÃ¶r veritabanÄ± yÃ¼kleniyor...")
            self.vector_store = Chroma(
                persist_directory=self.vector_store_path,
                embedding_function=self.embeddings
            )
        
        results = self.vector_store.similarity_search(query, k=k)
        return results