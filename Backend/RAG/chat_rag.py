# chat_rag.py
from rag_processor import RAGProcessor
from gemini_client import GeminiClient
import os
import shutil
import time
import warnings

warnings.filterwarnings('ignore')

class RAGChatbot:
    def __init__(self):
        self.rag_processor = RAGProcessor()
        self.gemini_client = GeminiClient()
        self.conversation_history = []
    
    def query(self, question):
        # Benzer iÃ§erikleri bul
        similar_docs = self.rag_processor.search_similar(question, k=5)
        
        if not similar_docs:
            return "âŒ Ä°lgili iÃ§erik bulunamadÄ±. LÃ¼tfen daha farklÄ± bir soru deneyin.", []
            
        context = "\n".join([doc.page_content for doc in similar_docs])
        
        # Gemini'ye sor
        response = self.gemini_client.generate_response(question, context)
        
        # KonuÅŸma geÃ§miÅŸine ekle
        self.conversation_history.append({
            "soru": question,
            "cevap": response
        })
        
        return response, similar_docs
    
    def show_sources(self, sources):
        """KaynaklarÄ± gÃ¶ster (tekrarsÄ±z + chunk sayÄ±sÄ±)"""
        if sources:
            # Kaynak isimlerine gÃ¶re chunk sayÄ±sÄ±nÄ± say
            source_counts = {}
            for doc in sources:
                source = doc.metadata.get('source', 'Bilinmeyen')
                source_name = os.path.basename(source)
                source_counts[source_name] = source_counts.get(source_name, 0) + 1
            
            print("\nğŸ“š KAYNAKLAR:")
            for i, (source_name, count) in enumerate(source_counts.items(), 1):
                if count > 1:
                    print(f"  {i}. {source_name} ({count} bÃ¶lÃ¼m)")
                else:
                    print(f"  {i}. {source_name}")

def setup_vector_store():
    """VektÃ¶r veritabanÄ±nÄ± kontrol et ve gerekirse oluÅŸtur"""
    vector_store_path = "vector_store"
    
    if os.path.exists(vector_store_path):
        try:
            from langchain_chroma import Chroma
            from langchain_huggingface import HuggingFaceEmbeddings
            
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
            temp_store = Chroma(persist_directory=vector_store_path, embedding_function=embeddings)
            doc_count = temp_store._collection.count()
            
            del temp_store
            time.sleep(0.5)
            
            if doc_count > 0:
                print(f"âœ… VektÃ¶r veritabanÄ± hazÄ±r ({doc_count} dokÃ¼man)")
                return True
            else:
                print("âš ï¸ VektÃ¶r veritabanÄ± boÅŸ!")
                return False
        except Exception as e:
            print(f"âš ï¸ VektÃ¶r veritabanÄ± hatasÄ±: {e}")
            return False
    else:
        print("âŒ VektÃ¶r veritabanÄ± bulunamadÄ±!")
        return False

def main():
    print("=" * 60)
    print("ğŸŒ± ORGANÄ°K TARIM ASISTANI ğŸŒ±".center(60))
    print("=" * 60)
    print()
    
    # VektÃ¶r veritabanÄ±nÄ± kontrol et
    if not setup_vector_store():
        print("\nğŸ“¥ PDF'ler iÅŸleniyor, lÃ¼tfen bekleyin...")
        rag_processor = RAGProcessor()
        rag_processor.load_and_process_pdfs()
        print("âœ… Ä°ÅŸlem tamamlandÄ±!")
    
    # Chatbot'u baÅŸlat
    chatbot = RAGChatbot()
    
    print("\nğŸ’¬ Merhaba! Organik tarÄ±m hakkÄ±nda sorularÄ±nÄ± cevaplayabilirim.")
    print("ğŸ“ Ä°pucu: 'Ã§Ä±kÄ±ÅŸ', 'exit' veya 'quit' yazarak Ã§Ä±kabilirsin.\n")
    print("=" * 60)
    
    while True:
        try:
            # KullanÄ±cÄ±dan soru al
            print("\n" + "â”€" * 60)
            user_input = input("ğŸ™‹ Sen: ").strip()
            
            # Ã‡Ä±kÄ±ÅŸ kontrolÃ¼
            if user_input.lower() in ['Ã§Ä±kÄ±ÅŸ', 'exit', 'quit', 'q', 'bye']:
                print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere! Ä°yi gÃ¼nler!")
                break
            
            # BoÅŸ input kontrolÃ¼
            if not user_input:
                print("âš ï¸ LÃ¼tfen bir soru yazÄ±n.")
                continue
            
            # Cevap al
            print("\nğŸ’­ DÃ¼ÅŸÃ¼nÃ¼yorum...", end="\r")
            response, sources = chatbot.query(user_input)
            print(" " * 50, end="\r")  # Temizle
            print(f"\nğŸ¤– Asistan:\n{response}")
            
            # KaynaklarÄ± gÃ¶ster
            chatbot.show_sources(sources)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere! Ä°yi gÃ¼nler!")
            break
        except Exception as e:
            print(f"\nâŒ Bir hata oluÅŸtu: {e}")
            print("LÃ¼tfen tekrar deneyin.")
    
    # KonuÅŸma Ã¶zeti
    if chatbot.conversation_history:
        print("\n" + "=" * 60)
        print(f"ğŸ“Š Toplam {len(chatbot.conversation_history)} soru cevaplandÄ±.")
        print("=" * 60)

if __name__ == "__main__":
    main()