#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Multi-Label Makine Ã–ÄŸrenmesi Analiz Scripti
final5.csv dosyasÄ±na Binary Relevance ile multi-label classification uygular
"""

import os
import sys
import pandas as pd
import numpy as np
import joblib
import json
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, hamming_loss, jaccard_score
from sklearn.multioutput import MultiOutputClassifier
import warnings
warnings.filterwarnings('ignore')

# Model dosyalarÄ±nÄ±n yolu
MODEL_DIR = os.path.join(os.path.dirname(__file__), "..", "Backend", "API", "MachineLearning", "Code", "model_outputs")

def train_multi_label_models(X, y_multi_label, crop_names):
    """Multi-label modelleri eÄŸitir - Binary Relevance ile"""
    print("ğŸ”„ Multi-label model eÄŸitimi baÅŸlÄ±yor...")
    
    try:
        from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
        from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier
        from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier
        from sklearn.svm import SVC
        from sklearn.neighbors import KNeighborsClassifier
        from sklearn.tree import DecisionTreeClassifier
        from sklearn.naive_bayes import GaussianNB
        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis
        from sklearn.neural_network import MLPClassifier
        import xgboost as xgb
        
        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_multi_label, test_size=0.2, random_state=42
        )
        
        # Feature scaling
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        print(f"ğŸ“Š EÄŸitim seti: {X_train.shape[0]} Ã¶rnek")
        print(f"ğŸ“Š Test seti: {X_test.shape[0]} Ã¶rnek")
        print(f"ğŸ“Š Label sayÄ±sÄ±: {y_multi_label.shape[1]}")
        
        # FarklÄ± algoritmalar
        models_and_params = {
            'RandomForest': {
                'model': RandomForestClassifier(random_state=42),
                'params': {
                    'estimator__n_estimators': [50, 100],
                    'estimator__max_depth': [None, 10, 20],
                    'estimator__min_samples_split': [2, 5]
                }
            },
            'LogisticRegression': {
                'model': LogisticRegression(random_state=42, max_iter=1000),
                'params': {
                    'estimator__C': [0.1, 1, 10],
                    'estimator__penalty': ['l1', 'l2'],
                    'estimator__solver': ['liblinear', 'saga']
                }
            },
            'SVM': {
                'model': SVC(random_state=42, probability=True),
                'params': {
                    'estimator__C': [0.1, 1, 10],
                    'estimator__kernel': ['rbf', 'poly'],
                    'estimator__gamma': ['scale', 'auto']
                }
            },
            'XGBoost': {
                'model': xgb.XGBClassifier(random_state=42, eval_metric='mlogloss'),
                'params': {
                    'estimator__n_estimators': [50, 100],
                    'estimator__max_depth': [3, 6],
                    'estimator__learning_rate': [0.1, 0.2]
                }
            },
            'ExtraTrees': {
                'model': ExtraTreesClassifier(random_state=42),
                'params': {
                    'estimator__n_estimators': [50, 100],
                    'estimator__max_depth': [None, 10, 20],
                    'estimator__min_samples_split': [2, 5]
                }
            },
            'GradientBoosting': {
                'model': GradientBoostingClassifier(random_state=42),
                'params': {
                    'estimator__n_estimators': [50, 100],
                    'estimator__max_depth': [3, 5],
                    'estimator__learning_rate': [0.1, 0.2]
                }
            },
            'KNN': {
                'model': KNeighborsClassifier(),
                'params': {
                    'estimator__n_neighbors': [3, 5, 7],
                    'estimator__weights': ['uniform', 'distance'],
                    'estimator__metric': ['euclidean', 'manhattan']
                }
            },
            'DecisionTree': {
                'model': DecisionTreeClassifier(random_state=42),
                'params': {
                    'estimator__max_depth': [None, 10, 20],
                    'estimator__min_samples_split': [2, 5],
                    'estimator__min_samples_leaf': [1, 2]
                }
            }
        }
        
        best_model = None
        best_score = 0
        best_name = ""
        results = {}
        
        print(f"ğŸ”„ {len(models_and_params)} farklÄ± algoritma test edilecek...")
        
        for i, (name, config) in enumerate(models_and_params.items(), 1):
            print(f"\n[{i}/{len(models_and_params)}] ğŸ”„ {name} eÄŸitiliyor...")
            
            try:
                # SVM iÃ§in Ã¶zel kontrol - tek sÄ±nÄ±flÄ± label'larÄ± kontrol et
                if name == 'SVM':
                    # y_train'i numpy array'e Ã§evir
                    y_train_array = np.array(y_train)
                    
                    # Her label iÃ§in sÄ±nÄ±f sayÄ±sÄ±nÄ± kontrol et
                    single_class_labels = []
                    for i in range(y_train_array.shape[1]):
                        unique_classes = np.unique(y_train_array[:, i])
                        if len(unique_classes) == 1:
                            single_class_labels.append(i)
                    
                    if len(single_class_labels) > 0:
                        print(f"   âš ï¸ {len(single_class_labels)} label tek sÄ±nÄ±flÄ±, SVM atlanÄ±yor...")
                        continue
                
                # Multi-output classifier
                multi_model = MultiOutputClassifier(config['model'], n_jobs=-1)
                
                # Grid search
                grid_search = GridSearchCV(
                    multi_model, 
                    config['params'], 
                    cv=3,  # 3-fold CV
                    scoring='f1_macro',
                    n_jobs=-1,
                    verbose=0
                )
                
                # Modeli eÄŸit
                grid_search.fit(X_train_scaled, y_train)
                
                # En iyi modeli al
                best_model_cv = grid_search.best_estimator_
                
                # Tahminler
                y_pred = best_model_cv.predict(X_test_scaled)
                
                # Metrikler
                accuracy = accuracy_score(y_test, y_pred)
                f1_micro = f1_score(y_test, y_pred, average='micro')
                f1_macro = f1_score(y_test, y_pred, average='macro')
                hamming = hamming_loss(y_test, y_pred)
                jaccard = jaccard_score(y_test, y_pred, average='macro', zero_division=0)
                
                results[name] = {
                    'accuracy': accuracy,
                    'f1_micro': f1_micro,
                    'f1_macro': f1_macro,
                    'hamming_loss': hamming,
                    'jaccard_score': jaccard,
                    'best_params': grid_search.best_params_,
                    'model': best_model_cv,
                    'predictions': y_pred
                }
                
                print(f"âœ… {name}:")
                print(f"   Accuracy: {accuracy:.4f}")
                print(f"   F1-Micro: {f1_micro:.4f}")
                print(f"   F1-Macro: {f1_macro:.4f}")
                print(f"   Hamming Loss: {hamming:.4f}")
                print(f"   Jaccard Score: {jaccard:.4f}")
                
                # En iyi modeli gÃ¼ncelle (F1-Macro'ya gÃ¶re)
                if f1_macro > best_score:
                    best_score = f1_macro
                    best_model = best_model_cv
                    best_name = name
                    
            except Exception as e:
                print(f"âŒ {name} hatasÄ±: {e}")
                results[name] = {'error': str(e)}
        
        print(f"\nğŸ† En iyi model: {best_name} (F1-Macro: {best_score:.4f})")
        
        # SonuÃ§larÄ± sÄ±rala
        successful_results = {k: v for k, v in results.items() if 'error' not in v}
        sorted_results = sorted(successful_results.items(), key=lambda x: x[1]['f1_macro'], reverse=True)
        
        print("\nğŸ“Š MODEL SIRALAMASI (F1-Macro'ya gÃ¶re):")
        for i, (name, result) in enumerate(sorted_results, 1):
            print(f"{i:2d}. {name:20s} - F1-Macro: {result['f1_macro']:.4f}, Accuracy: {result['accuracy']:.4f}")
        
        # Metadata oluÅŸtur
        metadata = {
            'best_model': best_name,
            'best_f1_macro': best_score,
            'feature_names': list(X.columns),
            'crop_names': crop_names,
            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'all_results': results,
            'top_models': sorted_results[:3]  # En iyi 3 model
        }
        
        # En iyi modeli kaydet
        model_save_path = os.path.join(os.path.dirname(__file__), "multi_label_model.pkl")
        
        complete_model = {
            'model': best_model,
            'scaler': scaler,
            'metadata': metadata
        }
        
        joblib.dump(complete_model, model_save_path)
        print(f"âœ… En iyi model kaydedildi: {model_save_path}")
        
        return best_model, scaler, metadata, results, X_test, y_test
        
    except Exception as e:
        print(f"âŒ Model eÄŸitimi hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, None, None, None

def prepare_multi_label_data(df):
    """Multi-label veriyi hazÄ±rlar"""
    print("ğŸ”„ Multi-label veri hazÄ±rlama baÅŸlÄ±yor...")
    
    # Label sÃ¼tunlarÄ±nÄ± ayÄ±r
    label_columns = [col for col in df.columns if col.startswith('label_')]
    feature_columns = [col for col in df.columns if not col.startswith('label_')]
    
    print(f"ğŸ“Š Ã–zellik sÃ¼tunlarÄ±: {len(feature_columns)}")
    print(f"ğŸ“Š Label sÃ¼tunlarÄ±: {len(label_columns)}")
    
    # Ã–zellikler ve label'larÄ± ayÄ±r
    X = df[feature_columns]
    y_multi_label = df[label_columns]
    
    # Crop isimlerini Ã§Ä±kar
    crop_names = [col.replace('label_', '') for col in label_columns]
    
    print(f"ğŸ“Š Ã–zellik sayÄ±sÄ±: {X.shape[1]}")
    print(f"ğŸ“Š Ã–rnek sayÄ±sÄ±: {X.shape[0]}")
    print(f"ğŸŒ± ÃœrÃ¼n sayÄ±sÄ±: {len(crop_names)}")
    
    # Tek sÄ±nÄ±flÄ± label'larÄ± kontrol et
    single_class_labels = []
    for i, crop in enumerate(crop_names):
        unique_values = np.unique(y_multi_label.iloc[:, i])
        if len(unique_values) == 1:
            single_class_labels.append(crop)
    
    if single_class_labels:
        print(f"âš ï¸ Tek sÄ±nÄ±flÄ± Ã¼rÃ¼nler bulundu: {single_class_labels}")
        print("Bu Ã¼rÃ¼nler analizden Ã§Ä±karÄ±lacak...")
        
        # Tek sÄ±nÄ±flÄ± label'larÄ± Ã§Ä±kar
        valid_labels = []
        for i, crop in enumerate(crop_names):
            if crop not in single_class_labels:
                valid_labels.append(i)
        
        y_multi_label = y_multi_label.iloc[:, valid_labels]
        crop_names = [crop for crop in crop_names if crop not in single_class_labels]
        
        print(f"âœ… GeÃ§erli Ã¼rÃ¼n sayÄ±sÄ±: {len(crop_names)}")
    else:
        print("âœ… TÃ¼m Ã¼rÃ¼nler Ã§ok sÄ±nÄ±flÄ±")
    
    # Kategorik sÃ¼tunlarÄ± sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼r
    categorical_columns = X.select_dtypes(include=['object']).columns
    if len(categorical_columns) > 0:
        print(f"ğŸ”„ Kategorik sÃ¼tunlar iÅŸleniyor: {list(categorical_columns)}")
        for col in categorical_columns:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))
            print(f"âœ… {col} sÃ¼tunu sayÄ±sal deÄŸerlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼")
    else:
        print("âœ… Kategorik sÃ¼tun bulunamadÄ±")
    
    # TÃ¼m sÃ¼tunlarÄ± sayÄ±sal tipe dÃ¶nÃ¼ÅŸtÃ¼r
    X = X.astype(float)
    
    # Eksik deÄŸerleri kontrol et ve doldur
    print(f"ğŸ” Eksik deÄŸer kontrolÃ¼:")
    missing_values = X.isnull().sum()
    if missing_values.sum() > 0:
        print("âš ï¸ Eksik deÄŸerler bulundu, ortalama ile dolduruluyor...")
        X = X.fillna(X.mean())
    else:
        print("âœ… Eksik deÄŸer yok")
    
    # Sonsuz deÄŸerleri kontrol et
    inf_values = np.isinf(X.select_dtypes(include=[np.number])).sum()
    if inf_values.sum() > 0:
        print("âš ï¸ Sonsuz deÄŸerler bulundu, NaN ile deÄŸiÅŸtiriliyor...")
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.mean())
    
    return X, y_multi_label, crop_names

def generate_multi_label_report(results, crop_names, X_test, y_test):
    """Multi-label analiz raporu oluÅŸturur"""
    print("\nğŸ“ Multi-label raporu oluÅŸturuluyor...")
    
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("BINARY RELEVANCE MULTI-LABEL CLASSIFICATION RAPORU")
    report_lines.append("=" * 80)
    report_lines.append(f"Rapor Tarihi: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append(f"Toplam ÃœrÃ¼n SayÄ±sÄ±: {len(crop_names)}")
    report_lines.append("")
    
    # Model karÅŸÄ±laÅŸtÄ±rmasÄ±
    report_lines.append("MODEL KARÅILAÅTIRMASI")
    report_lines.append("-" * 40)
    
    successful_results = {k: v for k, v in results.items() if 'error' not in v}
    sorted_results = sorted(successful_results.items(), key=lambda x: x[1]['f1_macro'], reverse=True)
    
    for i, (name, result) in enumerate(sorted_results, 1):
        report_lines.append(f"{i}. {name}")
        report_lines.append(f"   Accuracy: {result['accuracy']:.4f}")
        report_lines.append(f"   F1-Micro: {result['f1_micro']:.4f}")
        report_lines.append(f"   F1-Macro: {result['f1_macro']:.4f}")
        report_lines.append(f"   Hamming Loss: {result['hamming_loss']:.4f}")
        report_lines.append(f"   Jaccard Score: {result['jaccard_score']:.4f}")
        report_lines.append("")
    
    # ÃœrÃ¼n bazlÄ± performans
    if successful_results:
        best_model_name = sorted_results[0][0]
        best_result = successful_results[best_model_name]
        
        report_lines.append("ÃœRÃœN BAZLI PERFORMANS")
        report_lines.append("-" * 40)
        
        y_pred = best_result['predictions']
        
        # y_test'i numpy array'e Ã§evir
        y_test_array = np.array(y_test)
        
        for i, crop in enumerate(crop_names):
            true_positives = np.sum((y_test_array[:, i] == 1) & (y_pred[:, i] == 1))
            false_positives = np.sum((y_test_array[:, i] == 0) & (y_pred[:, i] == 1))
            false_negatives = np.sum((y_test_array[:, i] == 1) & (y_pred[:, i] == 0))
            true_negatives = np.sum((y_test_array[:, i] == 0) & (y_pred[:, i] == 0))
            
            precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
            recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            report_lines.append(f"{crop}:")
            report_lines.append(f"   Precision: {precision:.4f}")
            report_lines.append(f"   Recall: {recall:.4f}")
            report_lines.append(f"   F1-Score: {f1:.4f}")
            report_lines.append(f"   True Positives: {true_positives}")
            report_lines.append("")
    
    report_lines.append("=" * 80)
    report_lines.append("RAPOR SONU")
    report_lines.append("=" * 80)
    
    return "\n".join(report_lines)


def main():
    """Ana fonksiyon"""
    print("ğŸš€ Multi-Label Makine Ã–ÄŸrenmesi Analizi BaÅŸlÄ±yor...")
    print("=" * 60)
    
    try:
        # CSV dosyasÄ±nÄ± yÃ¼kle
        csv_path = os.path.join(os.path.dirname(__file__), "final5.csv")
        print(f"ğŸ“ CSV dosyasÄ± yÃ¼kleniyor: {csv_path}")
        
        df = pd.read_csv(csv_path)
        print(f"âœ… CSV yÃ¼klendi: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun")
        
        # Multi-label veriyi hazÄ±rla
        X, y_multi_label, crop_names = prepare_multi_label_data(df)
        
        # Multi-label modelleri eÄŸit
        best_model, scaler, metadata, results, X_test, y_test = train_multi_label_models(
            X, y_multi_label, crop_names
        )
        
        if best_model is None:
            print("âŒ Model eÄŸitilemedi, iÅŸlem durduruluyor")
            return
        
        # Rapor oluÅŸtur
        report_content = generate_multi_label_report(results, crop_names, X_test, y_test)
        
        # Raporu dosyaya yaz
        report_path = os.path.join(os.path.dirname(__file__), "multi_label_report.txt")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… Rapor oluÅŸturuldu: {report_path}")
        
        # Ã–zet istatistikler
        print("\nğŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER")
        print("-" * 30)
        print(f"Toplam Ã–rnek: {len(X)}")
        print(f"Toplam ÃœrÃ¼n: {len(crop_names)}")
        print(f"En Ä°yi Model: {metadata['best_model']}")
        print(f"En Ä°yi F1-Macro: {metadata['best_f1_macro']:.4f}")
        
        print("\nğŸ‰ Multi-label analiz tamamlandÄ±!")
        
    except Exception as e:
        print(f"âŒ Hata oluÅŸtu: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
